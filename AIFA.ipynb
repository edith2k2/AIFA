{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RpaW9CCZOukm"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cac948f34d2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfaster_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastRCNNPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import pandas as pd\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'robot'\n",
    "]\n",
    "# Class definition for the model\n",
    "class ObjectDetectionModel(object):\n",
    "    '''\n",
    "        The blackbox object detection model (Faster RCNN for those who want to know).\n",
    "        Given an image as numpy array (3, H, W), it detects objects (generates their category ids and bounding boxes).\n",
    "    '''\n",
    "    # __init__ function\n",
    "    def __init__(self):\n",
    "        self.model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "        self.model.eval()\n",
    "\n",
    "    # function for calling the faster-rcnn model\n",
    "    def __call__(self, input):\n",
    "        '''\n",
    "            Arguments:\n",
    "                input (numpy array): A (3, H, W) array of numbers in [0, 1] representing the image.\n",
    "            Returns:\n",
    "                pred_boxes (list): list of bounding boxes, [[x1 y1 x2 y2], ..] where (x1, y1) are the coordinates of the top left corner \n",
    "                                    and (x2, y2) are the coordinates of the bottom right corner.\n",
    "                pred_class (list): list of predicted classes\n",
    "                pred_score (list): list of the probability (confidence) of prediction of each of the bounding boxes\n",
    "        '''\n",
    "        input_tensor = torch.from_numpy(input)\n",
    "        input_tensor = input_tensor.type(torch.FloatTensor)\n",
    "        input_tensor = input_tensor.unsqueeze(0)\n",
    "        predictions = self.model(input_tensor)\n",
    "        pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(predictions[0]['labels'].numpy())] # Get the Prediction Score\n",
    "        pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(predictions[0]['boxes'].detach().numpy())] # Bounding boxes\n",
    "        pred_score = list(predictions[0]['scores'].detach().numpy())\n",
    "        pred_t = [pred_score.index(x) for x in pred_score if x > threshold][-1] # Get list of index with score greater than threshold.\n",
    "        pred_boxes = pred_boxes[:pred_t+1]\n",
    "        pred_class = pred_class[:pred_t+1]\n",
    "        \n",
    "        return pred_boxes, pred_class, pred_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5auM4XNdSs-E",
    "outputId": "ab846d65-f868-4310-a962-1a2bf248a00a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonlines\n",
      "  Downloading jsonlines-2.0.0-py3-none-any.whl (6.3 kB)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-2.0.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/battalavamshi/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines\n",
    "import jsonlines\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "class Dataset(object):\n",
    "    '''\n",
    "        A class for the dataset that will return data items as per the given index\n",
    "    '''\n",
    "    def __init__(self, annotation_file, transforms = None):\n",
    "        '''\n",
    "            Arguments:\n",
    "            annotation_file: path to the annotation file\n",
    "            transforms: list of transforms (class instances)\n",
    "                        For instance, [<class 'RandomCrop'>, <class 'Rotate'>]\n",
    "        '''\n",
    "        self.annotation_file = annotation_file\n",
    "        self.transforms = transforms\n",
    "        self.img_path = ''\n",
    "        paths = self.annotation_file.split('/')[:-1]\n",
    "        for p in paths:\n",
    "            self.img_path += p + '/'\n",
    "        self.ann = []\n",
    "        with jsonlines.open(self.annotation_file) as reader:\n",
    "            for obj in reader:\n",
    "                self.ann.append(obj)\n",
    "    def __len__(self):\n",
    "        '''\n",
    "            return the number of data points in the dataset\n",
    "        '''\n",
    "        return len(self.ann)\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "            return the dataset element for the index: \"idx\"\n",
    "            Arguments:\n",
    "                idx: index of the data element.\n",
    "            Returns:\n",
    "                image: image (in the form of a numpy array) (shape: (3, H, W))\n",
    "                gt_bboxes: N X 5 array where N is the number of bounding boxes, each \n",
    "                            consisting of [class, x1, y1, x2, y2]\n",
    "                            x1 and x2 lie between 0 and width of the image,\n",
    "                            y1 and y2 lie between 0 and height of the image.\n",
    "            You need to do the following, \n",
    "            1. Extract the correct annotation using the idx provided.\n",
    "            2. Read the image and convert it into a numpy array (wont be necessary\n",
    "                with some libraries). The shape of the array would be (3, H, W).\n",
    "            3. Scale the values in the array to be with [0, 1].\n",
    "            4. Create a dictonary with both the image and annotations\n",
    "            4. Perform the desired transformations.\n",
    "            5. Return the transformed image and annotations as specified.\n",
    "        '''\n",
    "        curr_ann = self.ann[idx]\n",
    "        img_path = os.path.join(self.img_path, curr_ann['img_fn'])\n",
    "        image = Image.open(img_path)\n",
    "        if self.transforms is not None:\n",
    "            for transform in self.transforms:\n",
    "                image = transform(image)\n",
    "        # image.show()\n",
    "        img = np.asarray(image)\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        img = img/np.max(img)\n",
    "        return {'image': img, 'gt_bboxes': curr_ann['bboxes']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCZGoD17S63X"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/vector_anki_json.zip', 'r') #Opens the zip file in read mode\n",
    "zip_ref.extractall('/tmp/vector_anki_json') #Extracts the files into the /tmp folder\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "xPpfODJB0Xru",
    "outputId": "f9aa8608-2c11-4238-f6de-9965eb56ae05",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def experiment(annotation_file, detector):\n",
    "    '''\n",
    "        Function to perform the desired experiments\n",
    "        Arguments:\n",
    "        annotation_file: Path to annotation file\n",
    "        detector: The object detector\n",
    "        transforms: List of transformation classes\n",
    "        outputs: path of the output folder to store the images\n",
    "    '''\n",
    "    #Create the instance of the dataset\n",
    "    dataset = Dataset(annotation_file)\n",
    "    #Iterate over all data items\n",
    "    sample = dataset.__getitem__(2)\n",
    "    #Get the predictions from the detector.\n",
    "    print(sample['image'])\n",
    "    pred_boxes, pred_class = detector.forward(sample['image'])\n",
    "    #Draw the boxes on the image and save them\n",
    "    show_boxes(sample['image'], pred_boxes[0:3], pred_class[0:3])\n",
    "def main():\n",
    "    detector = ObjectDetectionModel()\n",
    "    experiment('./tmp/vector_anki_json/train/_annotations.coco.json', detector)\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLJmjNECFfOo"
   },
   "outputs": [],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g69L7y24FjaQ"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AIFA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
